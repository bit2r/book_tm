---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
source("_common.R")

knitr::knit_hooks$set(output = function(x, options){
  paste0(
    '<pre class="r-output"><code>',
    fansi::sgr_to_html(x = htmltools::htmlEscape(x), warn = FALSE),
    '</code></pre>'
  )
})

```


# 텍스트 살펴보기 {#view-text}

## 특정 단어 강조 {#text-highlight}

윤석열 대통령 취임사 텍스트를 `취임사_윤석열.txt` 파일로 저장한 후에 
특정 단어 **자유** 를 탐색하여 색상을 달리하여 출력해보자. 

```{r view-crayon}
## 기본 텍스트 패키지
library(tidyverse)
library(tidytext)
## 한국 텍스트 처리 패키지
# library(RMeCab)
# library(bitTA)
## 글 색상
library(glue)
library(crayon)
library(fansi)
options(crayon.enabled = TRUE)


yoon_raw <- read_lines("data/취임사_윤석열.txt")

yoon_txt <- yoon_raw[yoon_raw !=""]

crayon_words <- function(input_text, word = "자유") {

  replaced_text <- str_replace_all(input_text, word, "{red {word}}")

  for(i in 1:length(replaced_text)) {
    crayon_text <- glue::glue_col(deparse(replaced_text[[i]]))
    print(crayon_text)
  }
}

crayon_words(input_text = yoon_txt, "자유")
```


## 단어 위치 {#text-highlight-locatin}

윤석열 대통령 취임사에서 가장 빈도수가 높은 명사 5개를 찾아낸다.
이를 위해서 먼저 텍스트를 각행별로 텍스트를 데이터프레임으로 변환시킨다.
그리고 나서 메카브(MeCab) 형태소 분석기를 사용해서 연설문 형태소 분석을 수행하고 
명사만 추출한 후에 가장 빈도수가 높은 단어 3개를 뽑아낸다.


```{r youn-top-five}
library(RcppMeCab)
library(tidytext)

yoon_tbl <- yoon_txt %>% 
  enframe(name = "행", value = "text") %>% 
  filter(text != "") 


youn_noun <- yoon_tbl %>% 
  unnest_tokens( output = 분석_텍스트,
                 input = text, 
                 token = RcppMeCab::pos) %>% 
  separate(분석_텍스트, c("명사", "형태소"), sep = "/") %>% 
  filter(형태소 == "nng") %>% 
  count(명사, sort = TRUE, name = "빈도수")

youn_top_three <- youn_noun %>% 
  slice_max(빈도수, n = 3) %>% 
  pull(명사)

youn_top_three
```

윤 대통령 취임사에서 가장 많이 언급된 명사 3개(자유, 국민, 시민)가 취임사 어느 
부분에 위치하는지 시각화를 한다. 이를 위해서 [`ggpage`](https://cran.r-project.org/web/packages/ggpage/)
패키지를 활용하여 `ggpage_build()` 함수와 `ggpage_plot()` 함수를 사용하여 깔끔하게 시각화한다.

```{r youn-top-five-ggpage, out.width='100%'}
library(ggpage)

yoon_tbl %>%
  ggpage_build(wtl = TRUE, lpp = 30, x_space_pages =10, y_space_pages = 0, nrow = 1) %>%   
  unnest_tokens( output = 분석_텍스트,
                 input = word, 
                 token = RcppMeCab::pos,
                 drop = FALSE) %>% 
  separate(분석_텍스트, c("명사", "형태소"), sep = "/") %>% 
  mutate(highlight = case_when(명사 %in% c("자유") ~ "자유",
                               명사 %in% c("국민") ~ "국민",
                               명사 %in% c("시민") ~ "시민",
                               TRUE ~ "기타"))  %>% 
  mutate(highlight = factor(highlight, levels=c("자유", "국민", "시민", "기타"))) %>% 
  ggpage_plot(aes(fill = highlight),
              paper.show = TRUE, page.number = "top", paper.limits = 3) +
  scale_fill_manual(values = c("blue", "red", "green", "darkgray")) +
  labs(title = "2022 윤석열 대통령 취임사",
       fill = NULL) +
  theme_void(base_family = "NanumGothic")  

```

## 취임사 요약

Ainize Teachable-NLP를 사용한 [kobart 문서요약 텍스트/신문기사](https://huggingface.co/ainize/kobart-news)를 사용하여 윤 대통령 취임사를 요약한다.


```{python yoon-text-summary, eval = FALSE}
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration
#  사전 훈련 토큰, 모형 다운로드
tokenizer = PreTrainedTokenizerFast.from_pretrained("ainize/kobart-news")
model = BartForConditionalGeneration.from_pretrained("ainize/kobart-news")
# 입력 텍스트
with open('data/취임사_윤석열.txt') as f:
  input_text = f.read()

import re

input_text = re.sub(r"\n", " ", input_text)



input_ids = tokenizer.encode(input_text, return_tensors="pt")
# Generate Summary Text Ids
summary_text_ids = model.generate(
    input_ids=input_ids,
    bos_token_id=model.config.bos_token_id,
    eos_token_id=model.config.eos_token_id,
    length_penalty=2.0,
    max_length=142,
    min_length=56,
    num_beams=4,
)
# Decoding Text
print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))
```

